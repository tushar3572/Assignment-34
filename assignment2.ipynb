{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42525965-35d3-4f18-bb54-f2c97e16cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 1\n",
    "    \n",
    "A random forest regressor. A random forest is a meta estimator that fits a number of decision tree regressors on \n",
    "various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa957f48-7a1f-4751-81cc-15ce842f19a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 2\n",
    "    \n",
    "By incorporating randomness, each tree in the forest exhibits low correlations with others, mitigating the risk of bias. Moreover, the presence of numerous trees helps alleviate overfitting,\n",
    "a situation where the model captures excessive “noise” from the training data, leading to suboptimal decisions.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32fcd6-c01b-4155-8717-715bbb4e79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 3\n",
    "    \n",
    "A random forest is a meta-estimator (i.e. it combines the result of multiple predictions), which aggregates many decision trees with some helpful modifications:\n",
    "The number of features that can be split at each node is limited to some percentage of the total (which is known as the hyper-parameter).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a319576a-616d-469a-8e53-22bd61cf2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 4\n",
    "    \n",
    "The Random Forest Regressor in scikit-learn has several hyperparameters that can be tuned for optimal performance. Here are some of the most important ones:\n",
    "\n",
    "1. **n_estimators**: The number of trees in the forest. More trees generally improve performance but also increase computational cost.\n",
    "  \n",
    "2. **max_depth**: The maximum depth of the trees in the forest. Deeper trees can capture more complex patterns in the data but may lead to overfitting.\n",
    "\n",
    "3. **min_samples_split**: The minimum number of samples required to split an internal node. Higher values prevent overfitting but may lead to underfitting.\n",
    "\n",
    "4. **min_samples_leaf**: The minimum number of samples required to be at a leaf node. Similar to `min_samples_split`, higher values prevent overfitting.\n",
    "\n",
    "5. **max_features**: The number of features to consider when looking for the best split. Lower values can reduce overfitting.\n",
    "\n",
    "6. **bootstrap**: Whether bootstrap samples are used when building trees. Setting it to True enables bootstrapping.\n",
    "\n",
    "7. **random_state**: Seed for random number generation. Provides reproducibility.\n",
    "\n",
    "8. **n_jobs**: The number of jobs to run in parallel for both `fit` and `predict`. Set to -1 to use all available cores.\n",
    "\n",
    "These are some of the key hyperparameters, but there are others that can be tuned as well, depending on the specific requirements of your problem.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d2f12a-91e6-4bab-a72f-8d629e16fc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 5\n",
    "    \n",
    "The Decision Tree Regressor produces 71.63% accuracy in predicting house prices on the Mumbai dataset, \n",
    "whereas the Random Forest Regression model produces 62.11% accuracy and with a significance score of 0.03 (p>0.05), there is a significant difference between two groups.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ae50b9-0c0c-4ddd-86f2-a6c3c76e0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 6\n",
    "    \n",
    "It can handle outliers and missing values, and does not require feature scaling as it uses rule based approach instead of distance calculation.\n",
    "Random forest provides information about the importance of each feature in the data, which can be very helpful in understanding the underlying patterns.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de4414-fd0a-41db-b8b7-4ec08659e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 7\n",
    "    \n",
    "Each decision tree regression predicts a number as an output for a given input.\n",
    "Random forest regression takes the average of those predictions as its 'final' output.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674af3c9-995b-4479-afd1-e4c8a10e195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 8\n",
    "    \n",
    "Random forest is a flexible, easy-to-use machine learning algorithm that produces, even without hyper-parameter tuning, a great result most of the time. \n",
    "It is also one of the most-used algorithms, due to its simplicity and diversity (it can be used for both classification and regression tasks).    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
